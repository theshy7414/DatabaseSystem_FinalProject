"""
Shop Data Loader for Neo4j
Â∞áÂïÜÂìÅË≥áÊñôËºâÂÖ• Neo4j ÂúñË≥áÊñôÂ∫´ÔºåÂª∫Á´ãËàáÈ¢®Ê†º„ÄÅÂìÅÁâå„ÄÅÈ°ûÂà•ÁöÑÈóú‰øÇ
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import openai
from neo4j import GraphDatabase
import ast
import time
import argparse
import logging
from typing import List, Dict
from config.settings import (
    OPENAI_API_KEY,
    NEO4J_URI,
    NEO4J_USER,
    NEO4J_PASSWORD,
    STYLE_PREDICTION_MODEL
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize OpenAI client
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# Initialize Neo4j driver
driver = None

STYLE_LIST = "Êó•Á≥ª„ÄÅÈüìÁ≥ª„ÄÅÊ≠êÁæé„ÄÅË°óÈ†≠„ÄÅÁ∞°Á¥Ñ„ÄÅÈÅãÂãïÈ¢®„ÄÅÂæ©Âè§„ÄÅ‰ºëÈñí„ÄÅÂ∑•Ë£ù„ÄÅÂÑ™ÈõÖ„ÄÅÊà∂Â§ñ„ÄÅÈÉΩÊúÉ„ÄÅÁîúÁæé„ÄÅÊÄßÊÑü„ÄÅÊ≠£Ë£ù„ÄÅËèØÈ∫ó"

PROMPT = """
‰Ω†ÊòØ‰∏ÄÂÄãÊôÇÂ∞öÁ©øÊê≠È¢®Ê†ºÂ∞àÂÆ∂„ÄÇÊ†πÊìö‰ª•‰∏ãË≥áË®äÔºåË´ãÂà§Êñ∑ÈÄôÈ†ÖÂïÜÂìÅÊúÄÁ¨¶ÂêàÁöÑ 1~2 ÂÄãÈ¢®Ê†ºÔºàÂæû‰∏ãÂàóÈ¢®Ê†ºÈÅ∏ÔºåÊúÄÂ§ö2ÂÄãÔºâÔºåÂè™ÂõûÂÇ≥ Python list Ê†ºÂºèÔºå‰∏çÈúÄËß£Èáã„ÄÅ‰∏çÈúÄË£úÂÖÖ„ÄÇ
ÂèØÈÅ∏È¢®Ê†ºÊúâÔºö{style_list}
Ë´ãÁî® ['È¢®Ê†º1', 'È¢®Ê†º2'] Êàñ ['È¢®Ê†º1'] Ê†ºÂºèÂõûÂÇ≥Ôºå‰∏çË¶ÅÊúâÂ§öÈ§òÊñáÂ≠ó„ÄÇ

---
ÂïÜÂìÅÂêçÁ®±Ôºö{item}
ÂïÜÂìÅÊèèËø∞Ôºö{desc}
È°ûÂà•Ôºö{category}
ÂìÅÁâåÔºö{brand}
---
"""


def init_neo4j():
    """ÂàùÂßãÂåñ Neo4j ÈÄ£Á∑ö"""
    global driver
    if driver is None:
        driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        logger.info("‚úÖ Connected to Neo4j")


def close_neo4j():
    """ÈóúÈñâ Neo4j ÈÄ£Á∑ö"""
    global driver
    if driver is not None:
        driver.close()
        driver = None
        logger.info("üîå Disconnected from Neo4j")


def predict_style(row: pd.Series) -> str:
    """‰ΩøÁî® LLM È†êÊ∏¨ÂïÜÂìÅÈ¢®Ê†º"""
    prompt = PROMPT.format(
        style_list=STYLE_LIST,
        item=row['name'],
        desc=row['description'],
        category=row.get('category', 'Êú™Áü•'),
        brand=row.get('brand', 'Êú™Áü•')
    )
    
    for retry in range(3):
        try:
            resp = client.chat.completions.create(
                model=STYLE_PREDICTION_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"Error predicting style (attempt {retry + 1}/3): {e}")
            time.sleep(2)
    return "[]"


def process_products(products_csv: str, products_csv_with_style: str, 
                    nrows: int = None, skip_prediction: bool = False) -> pd.DataFrame:
    """ËôïÁêÜÂïÜÂìÅË≥áÊñô‰∏¶È†êÊ∏¨È¢®Ê†º"""
    
    if skip_prediction and os.path.exists(products_csv_with_style):
        logger.info("üìÑ Skip prediction mode: Reading existing processed CSV")
        df = pd.read_csv(products_csv_with_style, nrows=nrows)
    else:
        logger.info("üìÑ Reading original CSV and predicting styles")
        df = pd.read_csv(products_csv, nrows=nrows)
        
        # ÊâπÊ¨°ËôïÁêÜÈ¢®Ê†ºÈ†êÊ∏¨
        logger.info(f"üîÆ Predicting styles for {len(df)} products...")
        df['predicted_style'] = df.apply(predict_style, axis=1)
        
        # ÂÑ≤Â≠òÁµêÊûú
        df.to_csv(products_csv_with_style, index=False)
        logger.info(f"üíæ Style prediction completed and saved to {products_csv_with_style}")
    
    return df


def create_product_node(tx, product_data: Dict):
    """Âú® Neo4j ‰∏≠ÂâµÂª∫ÂïÜÂìÅÁØÄÈªûÂèäÂÖ∂Èóú‰øÇ"""
    
    # ÂâµÂª∫ÂïÜÂìÅÁØÄÈªû
    query = """
    MERGE (p:Product {id: $id})
    SET p.name = $name,
        p.description = $description,
        p.price = $price,
        p.original_price = $original_price,
        p.image_url = $image_url,
        p.created_at = datetime()
    
    // ÂâµÂª∫ÂìÅÁâåÈóú‰øÇ
    MERGE (b:Brand {name: $brand})
    MERGE (p)-[:OF_BRAND]->(b)
    
    // ÂâµÂª∫È°ûÂà•Èóú‰øÇ
    MERGE (c:Category {name: $category})
    MERGE (p)-[:IN_CATEGORY]->(c)
    
    RETURN p.id as product_id
    """
    
    result = tx.run(query, **product_data)
    return result.single()['product_id']


def create_style_relationships(tx, product_id: str, styles: List[str]):
    """ÂâµÂª∫ÂïÜÂìÅËàáÈ¢®Ê†ºÁöÑÈóú‰øÇ"""
    
    query = """
    MATCH (p:Product {id: $product_id})
    UNWIND $styles as style_name
    MERGE (s:Style {name: style_name})
    MERGE (p)-[r:HAS_STYLE]->(s)
    SET r.confidence = 0.8
    RETURN count(r) as relationships_created
    """
    
    result = tx.run(query, product_id=product_id, styles=styles)
    return result.single()['relationships_created']


def import_to_neo4j(df: pd.DataFrame):
    """Â∞áÂïÜÂìÅË≥áÊñôÂåØÂÖ• Neo4j"""
    
    init_neo4j()
    
    total_rows = len(df)
    imported_rows = 0
    skipped_rows = 0
    
    logger.info(f"üöÄ Starting import of {total_rows} products to Neo4j...")
    
    with driver.session() as session:
        for idx, row in df.iterrows():
            try:
                # Ëß£ÊûêÈ†êÊ∏¨ÁöÑÈ¢®Ê†º
                try:
                    styles = ast.literal_eval(row['predicted_style'])
                    if not isinstance(styles, list):
                        raise ValueError("predicted_style must be a list")
                    # ÈÅéÊøæÁÑ°ÊïàÈ¢®Ê†º
                    valid_styles = [s for s in styles if s in STYLE_LIST]
                    if not valid_styles:
                        valid_styles = ['ÂÖ∂‰ªñ']
                except (ValueError, SyntaxError) as e:
                    logger.warning(f"Invalid predicted_style at row {idx}: {e}, using default")
                    valid_styles = ['‰ºëÈñí']
                
                # Ê∫ñÂÇôÂïÜÂìÅË≥áÊñô
                product_data = {
                    'id': f"prod_{idx}",  # ÁîüÊàêÂîØ‰∏Ä ID
                    'name': str(row['name']),
                    'description': str(row['description']),
                    'category': str(row.get('category', 'ÂÖ∂‰ªñ')),
                    'brand': str(row.get('brand', 'Êú™Áü•ÂìÅÁâå')),
                    'price': float(row['price']) if pd.notna(row['price']) else 0.0,
                    'original_price': float(row.get('original_price', row['price'])) if pd.notna(row.get('original_price', row['price'])) else 0.0,
                    'image_url': str(row.get('image_url', ''))
                }
                
                # ÂâµÂª∫ÂïÜÂìÅÁØÄÈªûÂíåÂü∫Êú¨Èóú‰øÇ
                product_id = session.execute_write(create_product_node, product_data)
                
                # ÂâµÂª∫È¢®Ê†ºÈóú‰øÇ
                session.execute_write(create_style_relationships, product_id, valid_styles)
                
                imported_rows += 1
                
                # Ë®òÈåÑÈÄ≤Â∫¶
                if imported_rows % 50 == 0:
                    logger.info(f"Progress: {imported_rows}/{total_rows} products imported ({imported_rows/total_rows*100:.1f}%)")
                
            except Exception as e:
                logger.error(f"Error importing row {idx}: {e}")
                skipped_rows += 1
                continue
    
    logger.info(f"‚úÖ Import completed: {imported_rows} products imported, {skipped_rows} skipped")
    
    # È©óË≠âÂ∞éÂÖ•
    verify_import()


def verify_import():
    """È©óË≠âË≥áÊñôÂåØÂÖ•ÁµêÊûú"""
    
    with driver.session() as session:
        # Áµ±Ë®àÂïÜÂìÅÊï∏Èáè
        result = session.run("MATCH (p:Product) RETURN count(p) as count")
        product_count = result.single()['count']
        logger.info(f"üìä Total products in database: {product_count}")
        
        # Áµ±Ë®àÂìÅÁâåÊï∏Èáè
        result = session.run("MATCH (b:Brand) RETURN count(b) as count")
        brand_count = result.single()['count']
        logger.info(f"üìä Total brands: {brand_count}")
        
        # Áµ±Ë®àÈ°ûÂà•Êï∏Èáè
        result = session.run("MATCH (c:Category) RETURN count(c) as count")
        category_count = result.single()['count']
        logger.info(f"üìä Total categories: {category_count}")
        
        # Áµ±Ë®àÈ¢®Ê†ºÈóú‰øÇ
        result = session.run("MATCH ()-[r:HAS_STYLE]->() RETURN count(r) as count")
        style_rel_count = result.single()['count']
        logger.info(f"üìä Total HAS_STYLE relationships: {style_rel_count}")
        
        # È°ØÁ§∫ÁØÑ‰æãÂïÜÂìÅ
        result = session.run("""
            MATCH (p:Product)-[:HAS_STYLE]->(s:Style)
            MATCH (p)-[:OF_BRAND]->(b:Brand)
            MATCH (p)-[:IN_CATEGORY]->(c:Category)
            WITH p, collect(DISTINCT s.name) as styles, b.name as brand, c.name as category
            RETURN p.name as name, p.price as price, brand, category, styles
            LIMIT 3
        """)
        
        logger.info("\nüì¶ Sample products:")
        for record in result:
            logger.info(f"  - {record['name']} (${record['price']}) - {record['brand']} | {record['category']} | Styles: {', '.join(record['styles'])}")


def main(products_csv: str, products_csv_with_style: str, 
         nrows: int = None, skip_prediction: bool = False):
    """‰∏ªÂáΩÊï∏"""
    
    try:
        # ËôïÁêÜ CSV Êñá‰ª∂
        df = process_products(products_csv, products_csv_with_style, nrows, skip_prediction)
        
        # ÂåØÂÖ•Âà∞ Neo4j
        import_to_neo4j(df)
        
        logger.info("\nüéâ All done! Products successfully loaded into Neo4j")
        
    except Exception as e:
        logger.error(f"‚ùå Error in main process: {e}")
        raise
    finally:
        close_neo4j()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Load product data into Neo4j')
    parser.add_argument('--products_csv', 
                      default="data/queenshop_all_products.csv",
                      help='Path to original products CSV file')
    parser.add_argument('--products_csv_with_style',
                      default="data/queenshop_all_products_with_style.csv",
                      help='Path to output CSV file with predicted styles')
    parser.add_argument('--nrows', type=int, default=None,
                      help='Number of rows to process (optional, for testing)')
    parser.add_argument('--skip_prediction', action='store_true',
                      help='Skip style prediction and use existing processed CSV')
    
    args = parser.parse_args()
    
    main(args.products_csv, args.products_csv_with_style, args.nrows, args.skip_prediction)
